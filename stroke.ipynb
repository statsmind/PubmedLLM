{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:44:16.501791Z",
     "start_time": "2024-02-18T05:44:14.987453700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jameshu\\.conda\\envs\\python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import json\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "from functools import wraps\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from Bio import Entrez\n",
    "from math import ceil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from lxml import etree\n",
    "from zhipuai import ZhipuAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ai_client = ZhipuAI()\n",
    "Entrez.email = \"jameshu@live.ccom\"\n",
    "\n",
    "pubmed_ids = []\n",
    "retstart = 0\n",
    "retmax = 1000\n",
    "\n",
    "\n",
    "class Cache:\n",
    "    def __init__(self, root_path):\n",
    "        self.root_path = root_path\n",
    "\n",
    "    def bucket(self, name):\n",
    "        def decorator(func):\n",
    "            @wraps(func)\n",
    "            def decorated(*args, **kwargs):\n",
    "                sig = inspect.signature(func)\n",
    "                params = sig.parameters\n",
    "\n",
    "                param_names = [key for key in params.keys()]\n",
    "                param_dict = {}\n",
    "                param_dict.update(zip(params.keys(), args))\n",
    "                param_dict.update(kwargs)\n",
    "\n",
    "                for k in (params.keys() - param_dict.keys()):\n",
    "                    param_dict[k] = params[k].default\n",
    "\n",
    "                key = list(sorted(param_dict.items()))\n",
    "                key = json.dumps(key)\n",
    "                m = hashlib.md5()\n",
    "                m.update(key.encode('utf8'))\n",
    "                hashkey = m.hexdigest()\n",
    "\n",
    "                cache_file = os.path.join(self.root_path, name, hashkey[0:2], hashkey)\n",
    "                os.makedirs(os.path.dirname(cache_file), 0o777, exist_ok=True)\n",
    "\n",
    "                if os.path.exists(cache_file):\n",
    "                    with open(cache_file, 'r', encoding='utf8') as fp:\n",
    "                        try:\n",
    "                            result = json.load(fp)\n",
    "                        except:\n",
    "                            result = None\n",
    "\n",
    "                        if result is not None:\n",
    "                            return result\n",
    "\n",
    "                result = func(*args, **kwargs)\n",
    "                if result is not None:\n",
    "                    with open(cache_file, 'w', encoding='utf8') as fp:\n",
    "                        fp.write(json.dumps(result))\n",
    "\n",
    "                return result\n",
    "\n",
    "            return decorated\n",
    "        return decorator\n",
    "\n",
    "\n",
    "cache = Cache(\".cache\")\n",
    "\n",
    "\n",
    "@cache.bucket(\"justscience\")\n",
    "def query_justscience(issn):\n",
    "    if issn is None or len(issn) == 0:\n",
    "        return None\n",
    "\n",
    "    response = requests.get(\n",
    "        f\"https://sci.justscience.cn/list?sci=1&q={issn}&research_area=&If_range_min=&If_range_max=&jcr_quartile=0&oa=2&Self_cites_ratio_min=&Self_cites_ratio_max=&mainclass=0&subclass=0&pub_country=&not_pub_country=&sci_type=2&pub_frequency=7&adv=1\")\n",
    "    root = etree.HTML(response.text)\n",
    "    tr_node = root.find(\".//table[@class=\\\"s-result-table\\\"]//tbody//tr\")\n",
    "    if tr_node is None:\n",
    "        response = requests.get(\n",
    "            f\"https://sci.justscience.cn/list?sci=0&q={issn}&research_area=&If_range_min=&If_range_max=&jcr_quartile=0&oa=2&Self_cites_ratio_min=&Self_cites_ratio_max=&mainclass=0&subclass=0&pub_country=&not_pub_country=&sci_type=2&pub_frequency=7&adv=1\")\n",
    "        root = etree.HTML(response.text)\n",
    "        tr_node = root.find(\".//table[@class=\\\"s-result-table\\\"]//tbody//tr\")\n",
    "\n",
    "    if tr_node is None:\n",
    "        lines = []\n",
    "    else:\n",
    "        tr_text = etree.tostring(tr_node, method='text', encoding='utf8')\n",
    "        lines = tr_text.decode().split(\"\\n\")\n",
    "        lines = [line.strip() for line in lines]\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "@cache.bucket(\"efetch\")\n",
    "def fetch_pubmed(pmid):\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=pmid)\n",
    "    return handle.read().decode('utf8')\n",
    "\n",
    "\n",
    "@cache.bucket(\"esearch\")\n",
    "def search_pubmed(term, retmax: int = 2000):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", retmax=retmax, retstart=0, term=term, sort=\"Pub Date\")\n",
    "    return Entrez.read(handle)\n",
    "\n",
    "\n",
    "@cache.bucket(\"embedding\")\n",
    "def get_embedding(text):\n",
    "    response = ai_client.embeddings.create(input=text, model='embedding-2')\n",
    "    return response.data[0].embedding\n",
    "    # client = ZhipuAI(api_key=\"\")  # 填写您自己的APIKey\n",
    "    # response = client.chat.completions.create(\n",
    "    #     model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"user\", \"content\": \"作为一名营销专家，请为我的产品创作一个吸引人的slogan\"},\n",
    "    #         {\"role\": \"assistant\", \"content\": \"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息\"},\n",
    "    #         {\"role\": \"user\", \"content\": \"智谱AI开放平台\"},\n",
    "    #         {\"role\": \"assistant\", \"content\": \"智启未来，谱绘无限一智谱AI，让创新触手可及!\"},\n",
    "    #         {\"role\": \"user\", \"content\": \"创造一个更精准、吸引人的slogan\"}\n",
    "    #     ],\n",
    "    # )\n",
    "    # print(response.choices[0].message)\n",
    "\n",
    "\n",
    "def string_to_float(text) -> float:\n",
    "    try:\n",
    "        return float(text)\n",
    "    except:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def parse_pubmed(content: str):\n",
    "    root = etree.XML(content)\n",
    "\n",
    "    title_node = root.find(\".//ArticleTitle\")\n",
    "    if title_node is not None and title_node.text is not None:\n",
    "        title = title_node.text.strip()\n",
    "    else:\n",
    "        title = \"\"\n",
    "\n",
    "    abstract_node = root.find(\".//AbstractText\")\n",
    "    if abstract_node is not None and abstract_node.text is not None:\n",
    "        abstract = abstract_node.text.strip()\n",
    "    else:\n",
    "        abstract = \"\"\n",
    "\n",
    "    issn_node = root.find(\".//ISSN\")\n",
    "    if issn_node is not None and issn_node.text is not None:\n",
    "        issn = issn_node.text.strip()\n",
    "    else:\n",
    "        issn = \"\"\n",
    "\n",
    "    return dict(title=title, abstract=abstract, issn=issn)\n",
    "\n",
    "\n",
    "candidates = []\n",
    "\n",
    "search_result = search_pubmed(\"stroke\")\n",
    "for idx, pmid in enumerate(search_result['IdList']):\n",
    "    content = fetch_pubmed(pmid)\n",
    "    info = parse_pubmed(content)\n",
    "\n",
    "    if_info = query_justscience(info['issn'])\n",
    "    if if_info is None or len(if_info) == 0 or len(info['title']) < 30 or string_to_float(if_info[7]) < 4.0:\n",
    "        continue\n",
    "\n",
    "    info['embedding'] = get_embedding(info['title'] + \"\\n\" + info['abstract'])\n",
    "    candidates.append(info)\n",
    "\n",
    "for idx, candidate in enumerate(candidates):\n",
    "    candidate['index'] = idx\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = [info['embedding'] for info in candidates]\n",
    "\n",
    "# 把所有文章分成10个类\n",
    "cluster = KMeans(n_clusters=10, random_state=0).fit(X)\n",
    "for idx, label in enumerate(cluster.labels_):\n",
    "    candidates[idx]['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[  0],\n        [  1],\n        [  2],\n        [  3],\n        [  4],\n        [  5],\n        [  6],\n        [  7],\n        [  8],\n        [  9],\n        [ 10],\n        [ 11],\n        [ 12],\n        [ 13],\n        [ 14],\n        [ 15],\n        [ 16],\n        [ 17],\n        [ 18],\n        [ 19],\n        [ 20],\n        [ 21],\n        [ 22],\n        [ 23],\n        [ 24],\n        [ 25],\n        [ 26],\n        [ 27],\n        [ 28],\n        [ 29],\n        [ 30],\n        [ 31],\n        [ 32],\n        [ 33],\n        [ 34],\n        [ 35],\n        [ 36],\n        [ 37],\n        [ 38],\n        [ 39],\n        [ 40],\n        [ 41],\n        [ 42],\n        [ 43],\n        [ 44],\n        [ 45],\n        [ 46],\n        [ 47],\n        [ 48],\n        [ 49],\n        [ 50],\n        [ 51],\n        [ 52],\n        [ 53],\n        [ 54],\n        [ 55],\n        [ 56],\n        [ 57],\n        [ 58],\n        [ 59],\n        [ 60],\n        [ 61],\n        [ 62],\n        [ 63],\n        [ 64],\n        [ 65],\n        [ 66],\n        [ 67],\n        [ 68],\n        [ 69],\n        [ 70],\n        [ 71],\n        [ 72],\n        [ 73],\n        [ 74],\n        [ 75],\n        [ 76],\n        [ 77],\n        [ 78],\n        [ 79],\n        [ 80],\n        [ 81],\n        [ 82],\n        [ 83],\n        [ 84],\n        [ 85],\n        [ 86],\n        [ 87],\n        [ 88],\n        [ 89],\n        [ 90],\n        [ 91],\n        [ 92],\n        [ 93],\n        [ 94],\n        [ 95],\n        [ 96],\n        [ 97],\n        [ 98],\n        [ 99],\n        [100],\n        [101],\n        [102],\n        [103],\n        [104],\n        [105],\n        [106],\n        [107],\n        [108],\n        [109],\n        [110],\n        [111],\n        [112],\n        [113],\n        [114],\n        [115],\n        [116],\n        [117],\n        [118],\n        [119],\n        [120],\n        [121],\n        [122],\n        [123],\n        [124],\n        [125],\n        [126],\n        [127],\n        [128],\n        [129],\n        [130],\n        [131],\n        [132],\n        [133],\n        [134],\n        [135],\n        [136],\n        [137],\n        [138],\n        [139],\n        [140],\n        [141],\n        [142],\n        [143],\n        [144],\n        [145],\n        [146],\n        [147],\n        [148],\n        [149],\n        [150],\n        [151],\n        [152],\n        [153],\n        [154],\n        [155],\n        [156],\n        [157],\n        [158],\n        [159],\n        [160],\n        [161],\n        [162],\n        [163],\n        [164],\n        [165],\n        [166],\n        [167],\n        [168],\n        [169],\n        [170],\n        [171],\n        [172],\n        [173],\n        [174],\n        [175],\n        [176],\n        [177],\n        [178],\n        [179],\n        [180],\n        [181],\n        [182],\n        [183],\n        [184],\n        [185],\n        [186],\n        [187],\n        [188],\n        [189],\n        [190],\n        [191],\n        [192],\n        [193],\n        [194],\n        [195],\n        [196],\n        [197],\n        [198],\n        [199],\n        [200],\n        [201],\n        [202],\n        [203],\n        [204],\n        [205],\n        [206],\n        [207],\n        [208],\n        [209],\n        [210],\n        [211],\n        [212],\n        [173],\n        [170],\n        [ 84],\n        [111],\n        [ 77],\n        [101],\n        [ 61],\n        [139],\n        [145],\n        [ 62],\n        [112],\n        [ 75],\n        [192],\n        [ 99],\n        [129],\n        [155],\n        [110],\n        [ 86],\n        [ 95],\n        [104],\n        [107],\n        [111],\n        [ 94],\n        [151],\n        [138],\n        [106],\n        [129],\n        [102],\n        [ 61],\n        [130],\n        [100],\n        [140],\n        [180],\n        [174],\n        [ 58],\n        [127],\n        [165],\n        [ 80],\n        [ 54],\n        [129],\n        [ 70],\n        [147],\n        [166],\n        [183],\n        [115],\n        [138],\n        [110],\n        [168],\n        [ 59],\n        [108],\n        [173],\n        [ 59],\n        [196],\n        [ 26],\n        [ 93],\n        [176],\n        [ 31],\n        [148],\n        [ 36],\n        [133],\n        [178],\n        [106],\n        [ 80],\n        [187],\n        [127],\n        [154],\n        [144],\n        [171],\n        [ 63],\n        [ 70],\n        [ 92],\n        [133],\n        [ 87],\n        [ 99],\n        [157],\n        [ 70],\n        [185],\n        [ 60],\n        [189],\n        [ 50],\n        [121],\n        [153],\n        [157],\n        [ 95],\n        [180],\n        [ 96],\n        [154],\n        [195],\n        [ 83],\n        [ 86],\n        [126],\n        [ 89],\n        [130],\n        [155],\n        [120],\n        [ 98],\n        [115],\n        [112],\n        [ 78],\n        [120],\n        [ 72],\n        [ 89],\n        [118],\n        [ 62],\n        [ 11],\n        [167],\n        [118],\n        [110],\n        [133],\n        [ 89],\n        [ 79],\n        [176],\n        [ 95],\n        [ 10],\n        [104],\n        [ 84],\n        [138],\n        [140],\n        [162],\n        [183],\n        [ 97],\n        [ 81],\n        [183],\n        [148],\n        [178],\n        [ 92],\n        [126],\n        [196],\n        [181],\n        [128],\n        [185],\n        [205],\n        [154],\n        [149],\n        [146],\n        [134],\n        [ 73],\n        [204],\n        [ 79],\n        [206],\n        [  3],\n        [ 24],\n        [187],\n        [ 28],\n        [145],\n        [183],\n        [ 12],\n        [ 10],\n        [128],\n        [ 16],\n        [117],\n        [ 10],\n        [ 13],\n        [ 13],\n        [ 66],\n        [ 82],\n        [165],\n        [ 53],\n        [195],\n        [ 79],\n        [ 72],\n        [200],\n        [ 69],\n        [ 77],\n        [125],\n        [ 55],\n        [168],\n        [207],\n        [ 51],\n        [127],\n        [134],\n        [ 54],\n        [145],\n        [199],\n        [206],\n        [201],\n        [ 75],\n        [201],\n        [133],\n        [192],\n        [ 82],\n        [ 82],\n        [ 21],\n        [ 39],\n        [ 22],\n        [  9],\n        [ 17],\n        [  7],\n        [ 37],\n        [ 35],\n        [112],\n        [ 59],\n        [ 41],\n        [ 40],\n        [119],\n        [ 25],\n        [ 38],\n        [  7],\n        [ 50],\n        [ 29],\n        [ 39],\n        [ 49],\n        [ 56],\n        [ 39],\n        [ 15],\n        [ 12],\n        [ 40]]),\n [7,\n  7,\n  1,\n  1,\n  9,\n  1,\n  1,\n  1,\n  9,\n  7,\n  5,\n  3,\n  7,\n  5,\n  9,\n  7,\n  9,\n  2,\n  7,\n  1,\n  1,\n  9,\n  1,\n  1,\n  1,\n  1,\n  9,\n  1,\n  7,\n  7,\n  3,\n  4,\n  8,\n  4,\n  3,\n  3,\n  1,\n  9,\n  1,\n  9,\n  9,\n  1,\n  9,\n  1,\n  1,\n  6,\n  1,\n  8,\n  2,\n  9,\n  7,\n  2,\n  4,\n  1,\n  1,\n  8,\n  9,\n  8,\n  0,\n  2,\n  9,\n  5,\n  1,\n  2,\n  4,\n  1,\n  4,\n  2,\n  3,\n  0,\n  1,\n  2,\n  5,\n  5,\n  4,\n  7,\n  6,\n  8,\n  4,\n  3,\n  8,\n  5,\n  3,\n  4,\n  6,\n  6,\n  4,\n  3,\n  7,\n  5,\n  5,\n  1,\n  4,\n  4,\n  1,\n  2,\n  7,\n  1,\n  4,\n  2,\n  0,\n  5,\n  0,\n  6,\n  4,\n  1,\n  3,\n  1,\n  2,\n  7,\n  5,\n  3,\n  0,\n  4,\n  2,\n  5,\n  1,\n  7,\n  4,\n  7,\n  5,\n  8,\n  9,\n  4,\n  8,\n  2,\n  3,\n  5,\n  2,\n  4,\n  1,\n  8,\n  7,\n  6,\n  6,\n  8,\n  7,\n  6,\n  1,\n  6,\n  9,\n  6,\n  3,\n  6,\n  2,\n  2,\n  6,\n  5,\n  7,\n  3,\n  4,\n  7,\n  3,\n  5,\n  4,\n  6,\n  4,\n  4,\n  0,\n  2,\n  2,\n  4,\n  1,\n  4,\n  8,\n  7,\n  1,\n  7,\n  3,\n  7,\n  4,\n  1,\n  1,\n  2,\n  0,\n  1,\n  6,\n  5,\n  7,\n  2,\n  2,\n  0,\n  6,\n  3,\n  4,\n  6,\n  7,\n  3,\n  8,\n  2,\n  1,\n  1,\n  8,\n  8,\n  3,\n  4,\n  4,\n  3,\n  1,\n  0,\n  2,\n  3,\n  6,\n  1,\n  8,\n  1,\n  7,\n  6,\n  7,\n  6,\n  8,\n  1,\n  2,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  3,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  4,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  5,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  6,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  7,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  8,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9,\n  9])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = np.reshape(range(len(candidates)), (-1, 1))\n",
    "y = [candidate['label'] for candidate in candidates]\n",
    "\n",
    "model_smote = SMOTE()\n",
    "x_smote_resampled, y_smote_resampled = model_smote.fit_resample(X, y)\n",
    "\n",
    "x_smote_resampled, y_smote_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:44:16.521770800Z",
     "start_time": "2024-02-18T05:44:16.504792Z"
    }
   },
   "id": "d16a582d462c1c34"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "label_groups = {}\n",
    "\n",
    "for x, y in zip(x_smote_resampled, y_smote_resampled):\n",
    "    if y not in label_groups:\n",
    "        label_groups[y] = []\n",
    "    \n",
    "    label_groups[y].append(candidates[x[0]])\n",
    "\n",
    "for key, values in label_groups.items():\n",
    "    random.shuffle(label_groups[key])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T05:44:19.433590600Z",
     "start_time": "2024-02-18T05:44:19.427527100Z"
    }
   },
   "id": "47d55085e685f555"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0\n",
      "processed 1\n",
      "processed 2\n",
      "processed 3\n",
      "processed 4\n",
      "processed 5\n",
      "processed 6\n",
      "processed 7\n",
      "processed 8\n",
      "processed 9\n",
      "processed 10\n",
      "processed 11\n",
      "processed 12\n",
      "processed 13\n"
     ]
    }
   ],
   "source": [
    "# 开始请求 AI\n",
    "\n",
    "num_loop = len(label_groups[0])\n",
    "num_loop = num_loop // 3\n",
    "\n",
    "fout = open(\"ideas.txt\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for loop in range(num_loop):\n",
    "    start = loop * 3\n",
    "    \n",
    "    candidates = {values[start]['index']: values[start] for key, values in label_groups.items()}\n",
    "    candidates.update({values[start + 1]['index']: values[start + 1] for key, values in label_groups.items()})\n",
    "    candidates.update({values[start + 2]['index']: values[start + 2] for key, values in label_groups.items()})\n",
    "    \n",
    "    candidates = list(candidates.values())\n",
    "    random.shuffle(candidates)\n",
    "    candidates = \"\\n\".join([str(idx + 1) + \"、\" + candidate['title'].strip() for idx, candidate in enumerate(candidates)])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "中国国家卒中登记研究-Ⅲ是一个多中心、前瞻性队列研究，拟通过标准诊断流程及目前公认的缺血性卒中病因分型，同时评价缺血性脑血管病相关危险因素，包括目前公认的血压、血脂、血糖等以及肾功能及心功能等预后影响因素，探索缺血性脑血管病病因及发病机制分布；在临床、影像、分子水平确定不同预后及其影响因素，探索包括影像学特征的TIA/卒中风险预测模型建立，认识卒中和TIA患者的预后影响因素，早期评估和识别高危患者。\n",
    "\n",
    "国内外前沿研究成果：\n",
    "{candidates}\n",
    "\n",
    "我想在中国国家卒中登记研究-Ⅲ队列研究基础上写一些论文。请参考国内外目前的相关领域前沿研究成果，扩展我的论文写作思路。每个思路展开说明主要研究背景，研究目的，方法，主要结局，危险因素，相关论文及影响因子。多想想再回答，思路不少于6个。输出格式为：\n",
    "\n",
    "研究背景：-- 研究背景\n",
    "研究目的：-- 研究目的\n",
    "方法：-- 方法\n",
    "主要结局：-- 主要结局\n",
    "危险因素：-- 危险因素\n",
    "相关论文及影响因子：-- 相关论文及影响因子\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    response = ai_client.chat.completions.create(\n",
    "        model=\"glm-3-turbo\",\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ])\n",
    "    \n",
    "    fout.write(response.choices[0].message.content + \"\\n\")\n",
    "    fout.flush()\n",
    "    print(f\"processed {loop}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-18T06:39:09.526450200Z",
     "start_time": "2024-02-18T06:34:17.150278200Z"
    }
   },
   "id": "93e504e7cf5bd5fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a3fdaf27d73344fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
